{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of the Glen-and-Isaacs and the Saltenis estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sobol_seq\n",
    "from string import ascii_lowercase\n",
    "import numba\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "k = 6 # number of parameters inquired\n",
    "\n",
    "# It is assumed the sm represents the dataframe on which we will be operating\n",
    "a2 = [0, 0.5, 3, 9, 99, 99]\n",
    "b3 = [6.52, 6.52, 6.52, 6.52, 6.52, 6.52]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@numba.jit    \n",
    "def A1(sm):\n",
    "    dummyA1 = pd.DataFrame()\n",
    "    for j in range(0,k):\n",
    "        dummyA1[j] = np.prod(sm[sm.columns[0:j+1]], axis = 1)*(-1)**(j+1)\n",
    "    return dummyA1.sum(axis=1)\n",
    "        \n",
    "def A2(sm):\n",
    "    dummyA2 = pd.DataFrame()\n",
    "    for j in range(0,k):\n",
    "        dummyA2[j] = (abs(4*sm[sm.columns[j]]-2)+a2[j])/(1+a2[j])\n",
    "    return (dummyA2.product(axis=1))\n",
    "        \n",
    "def B1(sm):\n",
    "    dummyB1 = pd.DataFrame()\n",
    "    for j in range(0,k):\n",
    "        dummyB1[j] = (k-sm[sm.columns[j]])/(k-0.5)\n",
    "    return dummyB1.product(axis=1)\n",
    "        \n",
    "def B2(sm):\n",
    "    dummyB2 = pd.DataFrame()\n",
    "    for j in range(0,k):\n",
    "        dummyB2[j] = (sm[sm.columns[j]])**(1/k)\n",
    "    return dummyB2.product(axis=1)*((1+1/k)**k)\n",
    "        \n",
    "def B3(sm):\n",
    "    dummyB3 = pd.DataFrame()\n",
    "    for j in range(0,k):\n",
    "        dummyB3[j] = (abs(4*sm[sm.columns[j]]-2)+b3[j])/(1+b3[j])\n",
    "    return (dummyB3.product(axis=1))\n",
    "        \n",
    "def C1(sm):\n",
    "    dummyC1 = pd.DataFrame()\n",
    "    for j in range(0,k):\n",
    "        dummyC1[j] = pd.Series(abs(4*sm[sm.columns[j]]-2))\n",
    "    return (dummyC1.product(axis=1))\n",
    "        \n",
    "def C2(sm):\n",
    "    return (sm.product(axis=1)*2**k)\n",
    "\n",
    "functions = [A1, A2, B1, B2, B3, C1, C2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And the analytical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#AEA1\n",
    "\n",
    "def Ek2(k):\n",
    "    return((1/6)*(1-(1/3)**k)+(4/15)*((-1)**(k+1)*(1/2)**k+(1/3)**k))\n",
    "\n",
    "def V(k):\n",
    "    return((1/10)*(1/3)**k+(1/18)-(1/9)*(1/2)**(2*k)+(-1)**(k+1)*(2/45)*(1/2)**k)\n",
    "\n",
    "for j in range(0, k):\n",
    "    def Ej(j):\n",
    "        return((1/6)*(1-(1/3)**(j))+(4/15)*((-1)**(j+1)*(1/2)**(j)+(1/3)**(j)))\n",
    "              \n",
    "    def T1(j):\n",
    "        return((1/2)*((1/3)**(j-1)*(1-(1/3)**(k-j))))\n",
    "\n",
    "    def T2(j):\n",
    "        return((1/2)*((1/3)**j-(1/3)**k))\n",
    "    \n",
    "    def T3(j):\n",
    "        return((3/5)*(4*(1/3)**(k+1)+(-1)**(j+k+1)*(1/2)**(k-j-2)*(1/3)**(j+1)))\n",
    "    \n",
    "    def T4(j):\n",
    "        return((1/5)*((-1)**(j+2)*(1/3)*(1/2)**(j-2)-4*(1/3)**(j+1)))\n",
    "    \n",
    "    def T5(j):\n",
    "        return((1/5)*((-1)**(k+1)*(1/3)*(1/2)**(k-2)+(-1)**(k+j)*(1/3)**(j+1)*(1/2)**(k-j-2)))\n",
    "    \n",
    "def A1ST(j):\n",
    "    return((Ek2(k)-Ej(j)-(1/4)*(T1(j)-2*T2(j)+T3(j))-T4(j)-T5(j))/V(k))\n",
    "\n",
    "#ÃEA2\n",
    "\n",
    "def VjA2(j):\n",
    "    return((1/3)/(1+a2[j])**2)\n",
    "\n",
    "def VA2(j):\n",
    "    productA2 = []\n",
    "    for j in range(0, k):\n",
    "        productA2.append(1+VjA2(j))\n",
    "    return np.product(productA2)-1\n",
    "\n",
    "def VnA2(j):\n",
    "    return((VA2(j)+1)/(1+VjA2(j)))\n",
    "\n",
    "def VTjA2(j):\n",
    "    return VjA2(j)*(VnA2(j))\n",
    "\n",
    "def A2ST(j):\n",
    "    return(VTjA2(j)/VA2(j))\n",
    "\n",
    "#AEB1\n",
    "\n",
    "def p(j):\n",
    "    return(12*(k-0.5)**2)\n",
    "        \n",
    "def B1ST(j):\n",
    "    return((p(j)+1)**k/((p(j)+1)*((p(j)+1)**k-p(j)**k)))\n",
    "\n",
    "#AEB2\n",
    "\n",
    "def B2ST(j):\n",
    "    return((k+1)**(2*k-2)/(((k+1)**(2*k)-(k**2+2*k)**k)))\n",
    "\n",
    "#AEB3\n",
    "\n",
    "def VjB3(j):\n",
    "    return((1/3)/(1+b3[j])**2)\n",
    "\n",
    "def VB3(j):\n",
    "    productB3 = []\n",
    "    for j in range(0, k):\n",
    "        productB3.append(1+VjB3(j))\n",
    "    return np.product(productB3)-1\n",
    "\n",
    "def VnB3(j):\n",
    "    return((VB3(j)+1)/(1+VjB3(j)))\n",
    "\n",
    "def VTjB3(j):\n",
    "    return VjB3(j)*(VnB3(j))\n",
    "\n",
    "def B3ST(j):\n",
    "    return(VTjB3(j)/VB3(j))\n",
    "\n",
    "#AEC1\n",
    "\n",
    "def C1ST(j):\n",
    "    return 4**(k-1)/(4**k-3**k)\n",
    "\n",
    "#AEC2\n",
    "        \n",
    "def C2ST(j):\n",
    "    return 4**(k-1)/(4**k-3**k)\n",
    "\n",
    "def create_dict(key, values):\n",
    "    return dict(zip(key, values))\n",
    "\n",
    "analyticalValues = [A1ST, A2ST, B1ST, B2ST, B3ST, C1ST, C2ST]\n",
    "\n",
    "AE = []\n",
    "AE_names = []\n",
    "for w in analyticalValues:\n",
    "    for j in range (0,k):\n",
    "        AE.append(w(j))\n",
    "        AE_names.append('AE' + str(w.__name__) + str(j+1))\n",
    "AE_dic = create_dict(AE_names, AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is then time to define the sample and scrambled matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "letters = []\n",
    "\n",
    "for l in ascii_lowercase:\n",
    "    letters.append(l)\n",
    "    \n",
    "p = 14\n",
    "run = 50\n",
    "\n",
    "n = 2\n",
    "\n",
    "p_sample = []\n",
    "p_sample_name = []\n",
    "\n",
    "p_sample_Jan = []\n",
    "p_sample_name_Jan = []\n",
    "\n",
    "df = pd.DataFrame(sobol_seq.i4_sobol_generate(k, run*2**p-4))\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qamples = []\n",
    "for s in range (2,p):\n",
    "    qamples.append(df.iloc[run*(-4+2**s):run*(-4+2**(s+1))].reset_index(drop=True))\n",
    "    \n",
    "    GIMAE_mean = []\n",
    "    CheckMAE_mean = []\n",
    "    \n",
    "    run_samples = []\n",
    "    for r in range (run):\n",
    "        run_samples.append(qamples[s-2].iloc[int(r*(len(qamples[s-2])/run)):int((r+1)*(len(qamples[s-2].\\\n",
    "        index)/run))].reset_index(drop=True))\n",
    "        \n",
    "        sample_Matrices = []\n",
    "        for m in range (n):\n",
    "            sample_Matrices.append(run_samples[r].iloc[int(m*(len(run_samples[r].index)/n)):int((m+1)*\\\n",
    "            (len(run_samples[r].index)/n))].reset_index(drop=True))\n",
    "                \n",
    "        sample_Matrices_dic = create_dict(letters, sample_Matrices)\n",
    "        \n",
    "            \n",
    "        mixed_Matrices = []\n",
    "        mm_names = []\n",
    "        for sm in range (0,len(sample_Matrices)):\n",
    "            for sm1 in range (0,len(sample_Matrices)):\n",
    "                if sm == sm1:\n",
    "                    continue\n",
    "                else:\n",
    "                    for c in sample_Matrices[sm]:\n",
    "                        mixed_Matrices.append(sample_Matrices[sm].copy())\n",
    "                        mixed_Matrices[len(mixed_Matrices)-1][c]=sample_Matrices[sm1].copy()[c]\n",
    "                        mm_names.append(str(letters[sm] + letters[sm1] + str(c+1)))\n",
    "        mixed_Matrices_dic = create_dict(mm_names, mixed_Matrices)\n",
    "        \n",
    "        matrices_dic = {**sample_Matrices_dic, **mixed_Matrices_dic}\n",
    "        \n",
    "        names = []\n",
    "        names1 = []\n",
    "        names2 = []\n",
    "        values = []\n",
    "        values1 = []\n",
    "        values2 = []\n",
    "        for f in functions:\n",
    "            for ss, zs in sample_Matrices_dic.items():\n",
    "                names.append(f.__name__+str(ss))\n",
    "                values.append(f(zs))\n",
    "    \n",
    "            for sq, zq in mixed_Matrices_dic.items():\n",
    "                names1.append(f.__name__+str(sq))\n",
    "                values1.append(f(zq))\n",
    "            \n",
    "            for sM, zM in matrices_dic.items():\n",
    "                names2.append(f.__name__+str(sM))\n",
    "                values2.append(f(zM))\n",
    "                \n",
    "        f_SM_dic = create_dict(names, values)\n",
    "        f_MM_dic = create_dict(names1, values1)\n",
    "        f_matrices_dic = create_dict(names2, values2)\n",
    "        \n",
    "        g_SM_dic = dict(f_SM_dic)\n",
    "        g_MM_dic = dict(f_MM_dic)\n",
    "        for mk, mv in f_SM_dic.items():\n",
    "            g_SM_dic[mk]=(mv-mv.mean())/(mv.var()**0.5)\n",
    "        for fk1, fv1 in f_MM_dic.items():\n",
    "            g_MM_dic[fk1]=(fv1-fv1.mean())/(fv1.var()**0.5)\n",
    "        \n",
    "        pk =[]\n",
    "        pk_name = []\n",
    "        cd = []\n",
    "        cdM = []\n",
    "        cd_name = []\n",
    "        cdM_name = []\n",
    "        for gk, gv in g_SM_dic.items():\n",
    "            for gk2, gv2 in g_SM_dic.items():\n",
    "                for j in range(1,k+1):\n",
    "                    if gk2[0:2]==gk[0:2] and gk2[2]!=gk[2] and gk[2]=='a':\n",
    "                        for gk1,gv1 in g_MM_dic.items():\n",
    "                            for gk3,gv3 in g_MM_dic.items():\n",
    "                                if gk3[0:2]==gk1[0:2]==gk[0:2] and gk3[2]!=gk1[2] and gk1[2]=='a' and gk1[-1]==gk3[-1]==str(j):\n",
    "                                    pk.append(0.5*(gv*gv2+gv1*gv3).mean())\n",
    "                                    cd.append(0.5*(gv*gv3+gv1*gv2).mean())\n",
    "                                    cdM.append(0.5*(gv*gv1+gv2*gv3).mean())\n",
    "                                    pk_name.append(str(gk3[0:2])+'pk'+str(j))\n",
    "                                    cd_name.append(str(gk3[0:2])+'cd'+str(j))\n",
    "                                    cdM_name.append(str(gk3[0:2])+'cd-'+str(j))\n",
    "        pk_dic = create_dict(pk_name, pk)\n",
    "        cd_dic = create_dict(cd_name, cd)\n",
    "        cdM_dic = create_dict(cdM_name, cdM)\n",
    "        \n",
    "        ca=[]\n",
    "        caM=[]\n",
    "        ca_name=[]\n",
    "        caM_name=[]\n",
    "        for cdk, cdv in cd_dic.items():\n",
    "            for cdMk, cdMv in cdM_dic.items():\n",
    "                for pkk, pkv in pk_dic.items():\n",
    "                    if pkk[0:2]==cdMk[0:2]==cdk[0:2] and pkk[-1]==cdMk[-1]==cdk[-1]:\n",
    "                        ca.append((cdv-pkv*cdMv)/(1-pkv**2))\n",
    "                        caM.append((cdMv-pkv*cdv)/(1-pkv**2))\n",
    "                        ca_name.append(str(pkk[0:2])+'ca'+str(pkk[-1]))\n",
    "                        caM_name.append(str(pkk[0:2])+'ca-'+str(pkk[-1]))\n",
    "        ca_dic = create_dict(ca_name, ca)\n",
    "        caM_dic = create_dict(caM_name, caM)\n",
    "        \n",
    "        ST = []\n",
    "        ST_name = []\n",
    "        for cdMk, cdMv in cdM_dic.items():\n",
    "            for pkk, pkv in pk_dic.items():\n",
    "                for cak, cav in ca_dic.items():\n",
    "                    for caMk, caMv in caM_dic.items():\n",
    "                        if caMk[0:2]==cak[0:2]==pkk[0:2]==cdMk[0:2] and caMk[-1]==cak[-1]==pkk[-1]==cdMk[-1]:\n",
    "                            ST.append(1-cdMv+pkv*cav/(1-cav*caMv))\n",
    "                            ST_name.append(str('GI_'+pkk[0:2]+'ST'+ pkk[-1]))\n",
    "        ST_dic = create_dict(ST_name, ST)\n",
    "        \n",
    "        GIMAEs = []\n",
    "        GIMAENames = []\n",
    "        for ae, av in AE_dic.items():\n",
    "            for Lk, Lv in ST_dic.items():\n",
    "                if ae[-5:]==Lk[-5:]:\n",
    "                    GIMAEs.append(abs(Lv-av))\n",
    "                    GIMAENames.append('GIMAE'+ str(ae[2:4]) + str(ae[-1]))\n",
    "        GIMAEs_dic = create_dict(GIMAENames, GIMAEs)\n",
    "        \n",
    "        GIMAE = []\n",
    "        GIMAE_name = []\n",
    "        for f in functions:\n",
    "            validkeys2 = []\n",
    "            for Lmk, Lmv in GIMAEs_dic.items():\n",
    "                if Lmk[-3:-1]==f.__name__:\n",
    "                    validkeys2.append(Lmk)\n",
    "            z2 = dict(filter(lambda i2:i2[0] in validkeys2, GIMAEs_dic.items()))\n",
    "            GIMAE.append(sum(z2.values())/len(z2))\n",
    "            GIMAE_name.append('GIMAE'+f.__name__)\n",
    "        GIMAE_dic = create_dict(GIMAE_name, GIMAE)\n",
    "        GIMAE_mean.append(GIMAE_dic)\n",
    "        \n",
    "        Check=[]\n",
    "        CheckName = []\n",
    "        for f in functions:\n",
    "            for j in range(1,k+1):\n",
    "                difference = []\n",
    "                for mk, mz in f_matrices_dic.items():\n",
    "                    if mk[0:2]==f.__name__:\n",
    "                        validkeys3 = []\n",
    "                        for fk1 in f_MM_dic.keys():\n",
    "                            if len(mk)==3: \n",
    "                                if mk[2] == 'a' and fk1[0:3]==mk[0:3] and fk1[-1]==str(j):\n",
    "                                    validkeys3.append(fk1)\n",
    "                            else: \n",
    "                                if fk1[0:3]==mk[0:3] and fk1[-1]==mk[-1] and fk1!=mk and fk1>=mk and fk1[-1]==str(j):\n",
    "                                    validkeys3.append(fk1)\n",
    "                        z1 = dict(filter(lambda i:i[0] in validkeys3, f_MM_dic.items()))\n",
    "                        for zk, zv in z1.items():\n",
    "                            difference.append(0.5*(((mz-zv)**2).mean())/mz.var())\n",
    "                Check.append(sum(difference)/len(difference))\n",
    "                CheckName.append('Jansen'+ str(f.__name__) +'ST'+str(j))\n",
    "        Check_dic = create_dict(CheckName, Check)\n",
    "                    \n",
    "        CheckMAEs = []\n",
    "        CheckMAENames = []\n",
    "        for ae, av in AE_dic.items():\n",
    "            for Jk, Jv in Check_dic.items():\n",
    "                if ae[-5:]==Jk[-5:]:\n",
    "                    CheckMAEs.append(abs(Jv-av))\n",
    "                    CheckMAENames.append('CheckMAE'+ str(ae[2:4]) + str(ae[-1]))\n",
    "        CheckMAEs_dic = create_dict(CheckMAENames, CheckMAEs)\n",
    "    \n",
    "        CheckMAE = []\n",
    "        CheckMAE_name = []\n",
    "        for f in functions:\n",
    "            validkeys4 = []\n",
    "            for Jmk, Jmv in CheckMAEs_dic.items():\n",
    "                if Jmk[-3:-1]==f.__name__:\n",
    "                    validkeys4.append(Jmk)\n",
    "            z2 = dict(filter(lambda i4:i4[0] in validkeys4, CheckMAEs_dic.items()))\n",
    "            CheckMAE.append(sum(z2.values())/len(z2))\n",
    "            CheckMAE_name.append('CheckMAE'+f.__name__)\n",
    "        CheckMAE_dic = create_dict(CheckMAE_name, CheckMAE)\n",
    "        CheckMAE_mean.append(CheckMAE_dic)\n",
    "        \n",
    "    GIMAE_mean_dic = {Lmk1:[GIMAE_mean[Lmv1][Lmk1] for Lmv1 in range(len(GIMAE_mean))] for Lmk1 in GIMAE_mean[0].keys()}\n",
    "    for Lmk1,Lmv1 in GIMAE_mean_dic.items():\n",
    "        GIMAE_mean_dic[Lmk1] = sum(GIMAE_mean_dic[Lmk1])/len(GIMAE_mean_dic[Lmk1])\n",
    "        \n",
    "    CheckMAE_mean_dic = {Jmk1:[CheckMAE_mean[Jmv1][Jmk1] for Jmv1 in range(len(CheckMAE_mean))] for Jmk1 in CheckMAE_mean[0].keys()}\n",
    "    for Jmk1,Jmv1 in CheckMAE_mean_dic.items():\n",
    "        CheckMAE_mean_dic[Jmk1] = sum(CheckMAE_mean_dic[Jmk1])/len(CheckMAE_mean_dic[Jmk1])\n",
    "        \n",
    "    p_sample.append(GIMAE_mean_dic)\n",
    "    p_sample_name.append((k+1)*2**s)\n",
    "    p_sample_Jan.append(CheckMAE_mean_dic)\n",
    "    p_sample_name_Jan.append((k+1)*2**(s-1))\n",
    "p_sample_dic = create_dict(p_sample_name, p_sample)\n",
    "p_sample_Jan_dic = create_dict(p_sample_name_Jan, p_sample_Jan)\n",
    "GlenIsaacs = pd.DataFrame.from_dict(p_sample_dic)\n",
    "Jansen_asym = pd.DataFrame.from_dict(p_sample_Jan_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sobol matrix gets sliced in a way that every sample is twice bigger than the previous qamples list elements. The qamples matrix gets in turn sliced in 50 parts of equivalent size. The rationale behind this operation is generating an adequate numbers of runs whose output can be averaged to compensate for fluctuations.\n",
    "\n",
    "Eventually, the two sample matrices are generated by slicing down the larger matrix in two parts of equal length. The code line sample_Matrices_dic creates a dictionary by appending the name in the alphabet sequence to the matrices in the order they have been generated (a, b). This operation can be ideally replicated in the case one wishes to compute more sample matrices for the estimators algorithm (ref. to the literature).\n",
    "\n",
    "The mixed matrices (i.e. ab1, ab6, ba2, etc.) are generated by scrambling the columns of the sample matrices. The first if excludes counting the same matrix twice, the second lower level for loop replicates the matrices the number of parameters one has and for each scrambles the relative column. Finally, the name is appended dependent the original matrix, the matrix whose column has been used for the scrambling and the number of the column. The label is eventually associated to the mixed matrices in the same way as done for the sample matrices. The sample and mixed matrices are zipped together into a matrices_dic.\n",
    "\n",
    "The functions are applied to the sets of matrices and the result of the operations are stored into dictionaries again. Now each item in the dictionaries f_MM_dic and f_matrices_dic is a vector rather than a matrix (f(a), f(b), f(ab4), etc.)\n",
    "\n",
    "For each function, the sample matrices are selected ('if len(mk)==3:'). From the ensamble of the scramble matrices, those having the same function and starting letter are selected for the total sensivity index accounting. While a different starting letter is the condition for the first-order estimator (fk1[2]!=mk[2]). The selection is based on the names (keys). The dictionary is filtered according to these criteria and the Jansen estimator-to-variance ratio is computed for the higher order (Check and CheckR) and the Sobol estimator-to-variance ratio for the first order matrices (Check3 and Check3R).\n",
    "\n",
    "Finally, the Mean Absolute Errors, the difference between the analytical value and the estimator figure, are computed and the values appended in a dictionary.\n",
    "\n",
    "These figures are then averaged on the different parameters (from six figures to one) as well as runs and stored in a dictionary CheckMAE_dic and CheckMAEF_dic.\n",
    "\n",
    "Which is in turn appended onto the final dictionary wrapping up all the experiments performed (up to the power of 2 'p' intially defined). This latter is eventually converted into a convenient pandas dataframe from which the trends can be easily plotted or statistically inference on the figures can be produced. The same applies to the Glen-and-Isaacs estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ind, row in GlenIsaacs.iterrows():\n",
    "    for indR, row in Jansen_asym.iterrows():\n",
    "        if ind[2:] == indR[-5:]:\n",
    "            x_vals = GlenIsaacs.columns.values\n",
    "            x2_vals = Jansen_asym.columns.values\n",
    "            y1 = GlenIsaacs.loc[ind]\n",
    "            y2 = Jansen_asym.loc[indR]\n",
    "            for i6 in range(0, len(x_vals), 1):\n",
    "                plt.loglog(x_vals[i6:i6+2], y1[i6:i6+2], c = \"b\", marker = \"o\", label = 'GI' if i6 == 0 else '')\n",
    "                plt.loglog(x2_vals[i6:i6+2], y2[i6:i6+2], c = \"r\", marker = \"o\", label = 'Jan' if i6 == 0 else '')\n",
    "                plt.title('Glen&IsaacsVsJansen_asym' + '_ST_' +str(ind[-2:]))\n",
    "                plt.xlim(110,58000)\n",
    "                plt.ylim(0,1)\n",
    "            plt.legend()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot finally allows to explore the trend across the sample dimension inquired."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
